{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20dee0c",
   "metadata": {},
   "source": [
    "# Polinomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea31c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8cf4df4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(700, 6)\n",
      "(700,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train = np.load(\"Data/X_train.npy\")\n",
    "Y_train = np.load(\"Data/Y_train.npy\")\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8ef2a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1: X_poly shape = (700, 6)\n",
      "Degree 1: R^2 = 0.5600\n",
      "\n",
      "Degree 2: X_poly shape = (700, 27)\n",
      "Degree 2: R^2 = 0.8298\n",
      "\n",
      "Degree 3: X_poly shape = (700, 83)\n",
      "Degree 3: R^2 = 0.8832\n",
      "\n",
      "Degree 4: X_poly shape = (700, 209)\n",
      "Degree 4: R^2 = 0.9817\n",
      "\n",
      "Degree 5: X_poly shape = (700, 461)\n",
      "Degree 5: R^2 = 0.9959\n",
      "\n",
      "Degree 6: X_poly shape = (700, 923)\n",
      "Degree 6: R^2 = 0.9998\n",
      "\n",
      "Degree 7: X_poly shape = (700, 1715)\n",
      "Degree 7: R^2 = 1.0000\n",
      "\n",
      "Degree 8: X_poly shape = (700, 3002)\n",
      "Degree 8: R^2 = 0.9999\n",
      "\n",
      "Degree 9: X_poly shape = (700, 5004)\n",
      "Degree 9: R^2 = 0.9994\n",
      "\n",
      "Degree 10: X_poly shape = (700, 8007)\n",
      "Degree 10: R^2 = 0.9983\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test polynomial degrees from 1 to 10\n",
    "for degree in range(1, 11):\n",
    "    # Generate polynomial features\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X_train)\n",
    "    \n",
    "    print(f\"Degree {degree}: X_poly shape = {X_poly.shape}\")\n",
    "    \n",
    "    # Fit regression model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, Y_train)\n",
    "    \n",
    "    # Predict on training data\n",
    "    Y_pred = model.predict(X_poly)\n",
    "    \n",
    "    # Compute R^2\n",
    "    r2 = r2_score(Y_train, Y_pred)\n",
    "    \n",
    "    print(f\"Degree {degree}: R^2 = {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2f38f",
   "metadata": {},
   "source": [
    "Split the data into train set (600 entries) and test set (100 entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dffb400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (600, 6) (600,)\n",
      "Test shape: (100, 6) (100,)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "X_train_input = np.load(\"Data/X_train.npy\")  # shape (700, 6)\n",
    "Y_train_input = np.load(\"Data/Y_train.npy\")  # shape (700,)\n",
    "    \n",
    "# Split data: first 500 train, last 200 test\n",
    "X_train, X_test = X_train_input[:600], X_train_input[600:]\n",
    "Y_train, Y_test = Y_train_input[:600], Y_train_input[600:]\n",
    "\n",
    "print(\"Train shape:\", X_train.shape, Y_train.shape)\n",
    "print(\"Test shape:\", X_test.shape, Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e81145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree 1: R² train = 0.5591, R² test = 0.5613\n",
      "Degree 2: R² train = 0.8302, R² test = 0.8151\n",
      "Degree 3: R² train = 0.8891, R² test = 0.8058\n",
      "Degree 4: R² train = 0.9834, R² test = 0.9223\n",
      "Degree 5: R² train = 0.9977, R² test = 0.2496\n",
      "Degree 6: R² train = 1.0000, R² test = -3.1742\n",
      "Degree 7: R² train = 1.0000, R² test = -626.6045\n",
      "Degree 8: R² train = 1.0000, R² test = -545568.5236\n",
      "Degree 9: R² train = 0.9997, R² test = -12926719.5196\n",
      "Degree 10: R² train = 0.9991, R² test = -36990070.4694\n"
     ]
    }
   ],
   "source": [
    "# Loop over polynomial degrees\n",
    "for degree in range(1, 11):\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    X_train_poly = poly.fit_transform(X_train)\n",
    "    X_test_poly = poly.transform(X_test)\n",
    "\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_poly, Y_train)\n",
    "\n",
    "    # Predictions\n",
    "    Y_pred_train = model.predict(X_train_poly)\n",
    "    Y_pred_test = model.predict(X_test_poly)\n",
    "\n",
    "    # R² scores\n",
    "    r2_train = r2_score(Y_train, Y_pred_train)\n",
    "    r2_test = r2_score(Y_test, Y_pred_test)\n",
    "\n",
    "    print(f\"Degree {degree}: R² train = {r2_train:.4f}, R² test = {r2_test:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a861f585",
   "metadata": {},
   "source": [
    "# Radial Basis Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2288d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "abdfda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train_input = np.load(\"Data/X_train.npy\")  # shape (700, 6)\n",
    "Y_train_input = np.load(\"Data/Y_train.npy\")  # shape (700,)\n",
    "\n",
    "# Split last 100 for test\n",
    "X_train_cv = X_train_input[:-100]\n",
    "Y_train_cv = Y_train_input[:-100]\n",
    "\n",
    "X_test_holdout = X_train_input[-100:]\n",
    "Y_test_holdout = Y_train_input[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42ae18d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_cv_scaled = scaler.fit_transform(X_train_cv)\n",
    "X_test_holdout_scaled = scaler.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "322900df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF transformation function\n",
    "def rbf_transform(X, centers, sigma):\n",
    "    diff = X[:, np.newaxis, :] - centers[np.newaxis, :, :]\n",
    "    return np.exp(-np.sum(diff**2, axis=2) / (2 * sigma**2))\n",
    "\n",
    "# Hyperparameter grids\n",
    "sigma_list = [0.1, 0.5, 1.0, 2.0]\n",
    "n_centers_list = [20, 50, 100]\n",
    "alpha_list = [0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# K-Fold CV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6ef177ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV R2: 0.9495841495380111\n",
      "Best hyperparameters: {'sigma': 2.0, 'n_centers': 100, 'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "for sigma, n_centers, alpha in product(sigma_list, n_centers_list, alpha_list):\n",
    "    \n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train_cv_scaled):\n",
    "        X_tr, X_val = X_train_cv_scaled[train_idx], X_train_cv_scaled[val_idx]\n",
    "        Y_tr, Y_val = Y_train_cv[train_idx], Y_train_cv[val_idx]\n",
    "        \n",
    "        # KMeans centers on training fold\n",
    "        kmeans = KMeans(n_clusters=n_centers, random_state=42).fit(X_tr)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Transform both training and validation data\n",
    "        X_tr_rbf = rbf_transform(X_tr, centers, sigma)\n",
    "        X_val_rbf = rbf_transform(X_val, centers, sigma)\n",
    "        \n",
    "        # Train Ridge regression\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_tr_rbf, Y_tr)\n",
    "        \n",
    "        # Predict on validation fold\n",
    "        Y_val_pred = model.predict(X_val_rbf)\n",
    "        r2_scores.append(r2_score(Y_val, Y_val_pred))\n",
    "    \n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    \n",
    "    if mean_r2 > best_r2:\n",
    "        best_r2 = mean_r2\n",
    "        best_params = {'sigma': sigma, 'n_centers': n_centers, 'alpha': alpha}\n",
    "\n",
    "print(\"Best CV R2:\", best_r2)\n",
    "print(\"Best hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b47f3874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on last 100 held-out samples: 0.9537986916830646\n"
     ]
    }
   ],
   "source": [
    "# Refit model on all 600 samples using best hyperparameters\n",
    "sigma_best = best_params['sigma']\n",
    "n_centers_best = best_params['n_centers']\n",
    "alpha_best = best_params['alpha']\n",
    "\n",
    "# KMeans centers on full training fold\n",
    "kmeans = KMeans(n_clusters=n_centers_best, random_state=42).fit(X_train_cv_scaled)\n",
    "centers_best = kmeans.cluster_centers_\n",
    "\n",
    "# Transform training and test data\n",
    "X_train_rbf = rbf_transform(X_train_cv_scaled, centers_best, sigma_best)\n",
    "X_test_rbf = rbf_transform(X_test_holdout_scaled, centers_best, sigma_best)\n",
    "\n",
    "# Train final model\n",
    "final_model = Ridge(alpha=alpha_best)\n",
    "final_model.fit(X_train_rbf, Y_train_cv)\n",
    "\n",
    "# Predict on held-out 100 samples\n",
    "Y_test_pred = final_model.predict(X_test_rbf)\n",
    "test_r2 = r2_score(Y_test_holdout, Y_test_pred)\n",
    "print(\"R2 on last 100 held-out samples:\", test_r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
