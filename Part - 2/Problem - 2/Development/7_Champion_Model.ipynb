{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09b9fcae",
   "metadata": {},
   "source": [
    "# Champion Model\n",
    "\n",
    "Model: Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5cb389",
   "metadata": {},
   "source": [
    "Hyperparameters:\n",
    "    'C': 10.0,\n",
    "    'kernel': 'poly',\n",
    "    'gamma': 0.01,\n",
    "    'degree': 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97332dd",
   "metadata": {},
   "source": [
    "Features: 18 best from Feature Engineering V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237d4634",
   "metadata": {},
   "source": [
    "# Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bc0873b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b2837bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define left and right side keypoints\n",
    "LEFT_SIDE_KEYPOINTS = [11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31]  # Left body parts\n",
    "RIGHT_SIDE_KEYPOINTS = [12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 32]  # Right body parts\n",
    "\n",
    "def calculate_velocity(sequence):\n",
    "    \"\"\"Calculate velocity between consecutive frames\"\"\"\n",
    "    # sequence shape: (seq_length, 33, 2)\n",
    "    velocity = np.diff(sequence, axis=0)  # (seq_length-1, 33, 2)\n",
    "    return velocity\n",
    "\n",
    "def calculate_side_velocity_stats(velocity_sequence, side_keypoints):\n",
    "    \"\"\"Calculate velocity statistics for a body side\"\"\"\n",
    "    # velocity_sequence shape: (seq_length-1, 33, 2)\n",
    "    side_velocity = velocity_sequence[:, side_keypoints, :]  # (seq_length-1, n_keypoints, 2)\n",
    "    \n",
    "    # Calculate magnitude of velocity vectors\n",
    "    velocity_magnitudes = np.sqrt(np.sum(side_velocity**2, axis=2))  # (seq_length-1, n_keypoints)\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    mean_velocity = np.mean(velocity_magnitudes)\n",
    "    std_velocity = np.std(velocity_magnitudes)\n",
    "    max_velocity = np.max(velocity_magnitudes)\n",
    "    \n",
    "    return mean_velocity, std_velocity, max_velocity\n",
    "\n",
    "def calculate_acceleration(velocity_sequence):\n",
    "    \"\"\"Calculate acceleration from velocity sequence\"\"\"\n",
    "    # velocity_sequence shape: (seq_length-1, 33, 2)\n",
    "    acceleration = np.diff(velocity_sequence, axis=0)  # (seq_length-2, 33, 2)\n",
    "    return acceleration\n",
    "\n",
    "def calculate_side_acceleration_stats(acceleration_sequence, side_keypoints):\n",
    "    \"\"\"Calculate acceleration statistics for a body side\"\"\"\n",
    "    # acceleration_sequence shape: (seq_length-2, 33, 2)\n",
    "    side_acceleration = acceleration_sequence[:, side_keypoints, :]  # (seq_length-2, n_keypoints, 2)\n",
    "    \n",
    "    # Calculate magnitude of acceleration vectors\n",
    "    acceleration_magnitudes = np.sqrt(np.sum(side_acceleration**2, axis=2))  # (seq_length-2, n_keypoints)\n",
    "    \n",
    "    # Aggregate statistics\n",
    "    mean_acceleration = np.mean(acceleration_magnitudes)\n",
    "    std_acceleration = np.std(acceleration_magnitudes)\n",
    "    max_acceleration = np.max(acceleration_magnitudes)\n",
    "    \n",
    "    return mean_acceleration, std_acceleration, max_acceleration\n",
    "\n",
    "def calculate_asymmetry_features(left_stats, right_stats):\n",
    "    \"\"\"Calculate asymmetry ratios between left and right sides\"\"\"\n",
    "    left_mean_vel, left_std_vel, left_max_vel = left_stats['velocity']\n",
    "    right_mean_vel, right_std_vel, right_max_vel = right_stats['velocity']\n",
    "    \n",
    "    left_mean_acc, left_std_acc, left_max_acc = left_stats['acceleration']\n",
    "    right_mean_acc, right_std_acc, right_max_acc = right_stats['acceleration']\n",
    "    \n",
    "    # Velocity asymmetry ratios\n",
    "    vel_mean_ratio = left_mean_vel / (right_mean_vel + 1e-8)  # Avoid division by zero\n",
    "    vel_std_ratio = left_std_vel / (right_std_vel + 1e-8)\n",
    "    vel_max_ratio = left_max_vel / (right_max_vel + 1e-8)\n",
    "    \n",
    "    # Acceleration asymmetry ratios\n",
    "    acc_mean_ratio = left_mean_acc / (right_mean_acc + 1e-8)\n",
    "    acc_std_ratio = left_std_acc / (right_std_acc + 1e-8)\n",
    "    acc_max_ratio = left_max_acc / (right_max_acc + 1e-8)\n",
    "    \n",
    "    return [vel_mean_ratio, vel_std_ratio, vel_max_ratio, \n",
    "            acc_mean_ratio, acc_std_ratio, acc_max_ratio]\n",
    "\n",
    "def extract_dynamic_features(df):\n",
    "    dynamic_features_list = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        skeleton_seq = np.array(row['Skeleton_Sequence'])\n",
    "\n",
    "\n",
    "        skeleton_seq = skeleton_seq.reshape(skeleton_seq.shape[0], 33, 2)\n",
    "\n",
    "        # Calculate velocity and acceleration\n",
    "        velocity = calculate_velocity(skeleton_seq)\n",
    "        acceleration = calculate_acceleration(velocity)\n",
    "        \n",
    "        # Calculate statistics for each side\n",
    "        left_vel_stats = calculate_side_velocity_stats(velocity, LEFT_SIDE_KEYPOINTS)\n",
    "        right_vel_stats = calculate_side_velocity_stats(velocity, RIGHT_SIDE_KEYPOINTS)\n",
    "        \n",
    "        left_acc_stats = calculate_side_acceleration_stats(acceleration, LEFT_SIDE_KEYPOINTS)\n",
    "        right_acc_stats = calculate_side_acceleration_stats(acceleration, RIGHT_SIDE_KEYPOINTS)\n",
    "        \n",
    "        # Create feature dictionaries\n",
    "        left_stats = {'velocity': left_vel_stats, 'acceleration': left_acc_stats}\n",
    "        right_stats = {'velocity': right_vel_stats, 'acceleration': right_acc_stats}\n",
    "        \n",
    "        # Calculate asymmetry features\n",
    "        asymmetry_features = calculate_asymmetry_features(left_stats, right_stats)\n",
    "        \n",
    "        # Combine all dynamic features\n",
    "        dynamic_features = [\n",
    "            *left_vel_stats, *right_vel_stats,\n",
    "            *left_acc_stats, *right_acc_stats,\n",
    "            *asymmetry_features\n",
    "        ]\n",
    "        \n",
    "        dynamic_features_list.append(dynamic_features)\n",
    "    \n",
    "    return np.array(dynamic_features_list)\n",
    "\n",
    "# Helper function to extract dynamic features for a single sequence\n",
    "def extract_dynamic_features_single(skeleton_seq):\n",
    "    \"\"\"Extract dynamic features for a single skeleton sequence\"\"\"\n",
    "    # Calculate velocity and acceleration\n",
    "    velocity = calculate_velocity(skeleton_seq)\n",
    "    acceleration = calculate_acceleration(velocity)\n",
    "    \n",
    "    # Calculate statistics for each side\n",
    "    left_vel_stats = calculate_side_velocity_stats(velocity, LEFT_SIDE_KEYPOINTS)\n",
    "    right_vel_stats = calculate_side_velocity_stats(velocity, RIGHT_SIDE_KEYPOINTS)\n",
    "    \n",
    "    left_acc_stats = calculate_side_acceleration_stats(acceleration, LEFT_SIDE_KEYPOINTS)\n",
    "    right_acc_stats = calculate_side_acceleration_stats(acceleration, RIGHT_SIDE_KEYPOINTS)\n",
    "    \n",
    "    # Create feature dictionaries\n",
    "    left_stats = {\n",
    "        'velocity': left_vel_stats,\n",
    "        'acceleration': left_acc_stats\n",
    "    }\n",
    "    right_stats = {\n",
    "        'velocity': right_vel_stats,\n",
    "        'acceleration': right_acc_stats\n",
    "    }\n",
    "    \n",
    "    # Calculate asymmetry features\n",
    "    asymmetry_features = calculate_asymmetry_features(left_stats, right_stats)\n",
    "    \n",
    "    # Combine all dynamic features\n",
    "    dynamic_features = [\n",
    "        *left_vel_stats, *right_vel_stats,    # 6 velocity features\n",
    "        *left_acc_stats, *right_acc_stats,    # 6 acceleration features  \n",
    "        *asymmetry_features                   # 6 asymmetry ratios\n",
    "    ]\n",
    "    \n",
    "    return np.array(dynamic_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b97e4990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create feature mask for top N features per exercise (BOTH static and dynamic)\n",
    "def create_top_n_mask(n_features_per_exercise, feature_importance_df):\n",
    "\n",
    "    # Create feature name to index mapping\n",
    "    keypoint_names = [\n",
    "        'nose', 'left_eye_inner', 'left_eye', 'left_eye_outer', 'right_eye_inner', 'right_eye', 'right_eye_outer',\n",
    "        'left_ear', 'right_ear', 'mouth_left', 'mouth_right', 'left_shoulder', 'right_shoulder',\n",
    "        'left_elbow', 'right_elbow', 'left_wrist', 'right_wrist', 'left_pinky', 'right_pinky',\n",
    "        'left_index', 'right_index', 'left_thumb', 'right_thumb', 'left_hip', 'right_hip',\n",
    "        'left_knee', 'right_knee', 'left_ankle', 'right_ankle', 'left_heel', 'right_heel',\n",
    "        'left_foot_index', 'right_foot_index'\n",
    "    ]\n",
    "\n",
    "    feature_to_index = {}\n",
    "    for i, name in enumerate(keypoint_names):\n",
    "        feature_to_index[f'{name}_mean_x'] = (i, 'mean_x')\n",
    "        feature_to_index[f'{name}_mean_y'] = (i, 'mean_y')\n",
    "        feature_to_index[f'{name}_var_x'] = (i, 'var_x')\n",
    "        feature_to_index[f'{name}_var_y'] = (i, 'var_y')\n",
    "\n",
    "    # Dynamic feature names and their indices (they come after the 132 static features)\n",
    "    dynamic_feature_names = [\n",
    "        'left_side_mean_velocity', 'left_side_std_velocity', 'left_side_max_velocity',\n",
    "        'right_side_mean_velocity', 'right_side_std_velocity', 'right_side_max_velocity',\n",
    "        'left_side_mean_acceleration', 'left_side_std_acceleration', 'left_side_max_acceleration',\n",
    "        'right_side_mean_acceleration', 'right_side_std_acceleration', 'right_side_max_acceleration',\n",
    "        'velocity_mean_asymmetry_ratio', 'velocity_std_asymmetry_ratio', 'velocity_max_asymmetry_ratio',\n",
    "        'acceleration_mean_asymmetry_ratio', 'acceleration_std_asymmetry_ratio', 'acceleration_max_asymmetry_ratio'\n",
    "    ]\n",
    "\n",
    "    # Add dynamic features to the mapping (they start at index 132)\n",
    "    for i, name in enumerate(dynamic_feature_names):\n",
    "        feature_to_index[name] = (132 + i, 'dynamic')\n",
    "\n",
    "    mask_dict = {}\n",
    "    \n",
    "    for exercise in ['E1', 'E2', 'E3', 'E4', 'E5']:\n",
    "        # Get top N features for this exercise (both static and dynamic)\n",
    "        top_features = feature_importance_df[\n",
    "            feature_importance_df['exercise'] == exercise\n",
    "        ].nlargest(n_features_per_exercise, 'importance')\n",
    "        \n",
    "        mask_dict[exercise] = {}\n",
    "        \n",
    "        for _, row in top_features.iterrows():\n",
    "            feature_name = row['feature']\n",
    "            if feature_name in feature_to_index:\n",
    "                feature_idx, feature_type = feature_to_index[feature_name]\n",
    "                \n",
    "                if feature_type == 'dynamic':\n",
    "                    # For dynamic features, we store them with a special key\n",
    "                    if 'dynamic' not in mask_dict[exercise]:\n",
    "                        mask_dict[exercise]['dynamic'] = set()\n",
    "                    mask_dict[exercise]['dynamic'].add(feature_idx - 132)  # Convert to dynamic feature index (0-17)\n",
    "                else:\n",
    "                    # For static features, use the original keypoint-based system\n",
    "                    kp_idx = feature_idx\n",
    "                    component = feature_type\n",
    "                    if kp_idx not in mask_dict[exercise]:\n",
    "                        mask_dict[exercise][kp_idx] = []\n",
    "                    if component not in mask_dict[exercise][kp_idx]:\n",
    "                        mask_dict[exercise][kp_idx].append(component)\n",
    "    \n",
    "    return mask_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3946c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined feature extraction function with top-N masking for BOTH static and dynamic features\n",
    "def extract_combined_features_with_masking(df, top_n_mask):\n",
    "    features_list = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        skeleton_seq = row['Skeleton_Sequence']\n",
    "        exercise_id = row['Exercise_Id']\n",
    "        \n",
    "        # Get feature mask configuration for this exercise\n",
    "        feature_mask_config = top_n_mask.get(exercise_id, {})\n",
    "        \n",
    "        # ===== EXTRACT STATIC FEATURES WITH MASKING =====\n",
    "        # Ensure skeleton_seq is 3D: (seq_length, 33, 2)\n",
    "        if skeleton_seq.ndim == 2 and skeleton_seq.shape[1] == 66:\n",
    "            skeleton_seq = skeleton_seq.reshape(skeleton_seq.shape[0], 33, 2)\n",
    "        \n",
    "        # Calculate means and variances for all keypoints first\n",
    "        flattened = skeleton_seq.reshape(len(skeleton_seq), -1)  # (seq_length, 66)\n",
    "        all_means = np.mean(flattened, axis=0)  # 66 features\n",
    "        all_variances = np.var(flattened, axis=0)  # 66 features\n",
    "        \n",
    "        # Apply granular masking - only keep specified static features\n",
    "        final_means = np.zeros(66)\n",
    "        final_variances = np.zeros(66)\n",
    "        \n",
    "        # For each keypoint in the mask configuration, keep specified components\n",
    "        for kp_idx, components_to_keep in feature_mask_config.items():\n",
    "            if kp_idx == 'dynamic':\n",
    "                continue  # Skip dynamic features for now\n",
    "            \n",
    "            # Each keypoint has 2 positions in the mean/variance arrays\n",
    "            mean_x_idx = kp_idx * 2\n",
    "            mean_y_idx = kp_idx * 2 + 1\n",
    "            var_x_idx = kp_idx * 2\n",
    "            var_y_idx = kp_idx * 2 + 1\n",
    "            \n",
    "            if 'mean_x' in components_to_keep:\n",
    "                final_means[mean_x_idx] = all_means[mean_x_idx]\n",
    "            if 'mean_y' in components_to_keep:\n",
    "                final_means[mean_y_idx] = all_means[mean_y_idx]\n",
    "            if 'var_x' in components_to_keep:\n",
    "                final_variances[var_x_idx] = all_variances[var_x_idx]\n",
    "            if 'var_y' in components_to_keep:\n",
    "                final_variances[var_y_idx] = all_variances[var_y_idx]\n",
    "        \n",
    "        static_features = np.concatenate([final_means, final_variances])\n",
    "        \n",
    "        # ===== EXTRACT DYNAMIC FEATURES WITH MASKING =====\n",
    "        dynamic_features_all = extract_dynamic_features_single(skeleton_seq)\n",
    "\n",
    "        # Dynamic feature names and their indices (they come after the 132 static features)\n",
    "        dynamic_feature_names = [\n",
    "            'left_side_mean_velocity', 'left_side_std_velocity', 'left_side_max_velocity',\n",
    "            'right_side_mean_velocity', 'right_side_std_velocity', 'right_side_max_velocity',\n",
    "            'left_side_mean_acceleration', 'left_side_std_acceleration', 'left_side_max_acceleration',\n",
    "            'right_side_mean_acceleration', 'right_side_std_acceleration', 'right_side_max_acceleration',\n",
    "            'velocity_mean_asymmetry_ratio', 'velocity_std_asymmetry_ratio', 'velocity_max_asymmetry_ratio',\n",
    "            'acceleration_mean_asymmetry_ratio', 'acceleration_std_asymmetry_ratio', 'acceleration_max_asymmetry_ratio'\n",
    "        ]\n",
    "        \n",
    "        # Apply masking to dynamic features\n",
    "        dynamic_features_masked = np.zeros(len(dynamic_feature_names))\n",
    "        if 'dynamic' in feature_mask_config:\n",
    "            dynamic_indices_to_keep = feature_mask_config['dynamic']\n",
    "            for idx in dynamic_indices_to_keep:\n",
    "                if idx < len(dynamic_features_all):\n",
    "                    dynamic_features_masked[idx] = dynamic_features_all[idx]\n",
    "        \n",
    "        # ===== COMBINE STATIC AND DYNAMIC FEATURES =====\n",
    "        combined_features = np.concatenate([static_features, dynamic_features_masked])\n",
    "        features_list.append(combined_features)\n",
    "    \n",
    "    return np.array(features_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "241c79e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_final_model():\n",
    "    # Configuration\n",
    "    TOP_FEATURES = 18\n",
    "    BEST_PARAMS = {\n",
    "        'C': 10.0,\n",
    "        'kernel': 'poly',\n",
    "        'gamma': 0.01,\n",
    "        'degree': 3\n",
    "    }\n",
    "    \n",
    "    # Load data\n",
    "    X_train = joblib.load(\"Data/Xtrain2.pkl\")\n",
    "    Y_train = np.load('Data/Ytrain2.npy')\n",
    "    \n",
    "    # Get patient IDs and create mappings\n",
    "    patient_ids = np.sort(X_train['Patient_Id'].unique())\n",
    "    all_patient_to_label = dict(zip(range(1, 15), Y_train))\n",
    "    patient_to_label = {pid: all_patient_to_label[pid] for pid in patient_ids}\n",
    "    \n",
    "    # Load feature importance and create mask for top 18 features\n",
    "    feature_importance_df = pd.read_csv('feature_importance_v2_baseline.csv')\n",
    "    top_n_mask = create_top_n_mask(TOP_FEATURES, feature_importance_df)\n",
    "    \n",
    "    # Extract features\n",
    "    X_combined_features = extract_combined_features_with_masking(X_train, top_n_mask)\n",
    "    \n",
    "    # Add exercise encoding\n",
    "    exercise_encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    exercise_encoded = exercise_encoder.fit_transform(X_train[['Exercise_Id']])\n",
    "    X_combined = np.concatenate([X_combined_features, exercise_encoded], axis=1)\n",
    "    \n",
    "    # Create sequence-level labels\n",
    "    y_sequences = X_train['Patient_Id'].map(patient_to_label).values\n",
    "    \n",
    "    # Create and train the final model\n",
    "    final_model = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svm', SVC(\n",
    "            C=BEST_PARAMS['C'],\n",
    "            kernel=BEST_PARAMS['kernel'],\n",
    "            gamma=BEST_PARAMS['gamma'],\n",
    "            degree=BEST_PARAMS['degree'],\n",
    "            class_weight='balanced',\n",
    "            probability=True,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    # Train on all data\n",
    "    final_model.fit(X_combined, y_sequences)\n",
    "    \n",
    "    # Create a dictionary with all components needed for prediction\n",
    "    model_artifacts = {\n",
    "        'model': final_model,\n",
    "        'feature_mask': top_n_mask,\n",
    "        'exercise_encoder': exercise_encoder,\n",
    "        'patient_to_label': patient_to_label,\n",
    "        'top_features': TOP_FEATURES,\n",
    "        'model_params': BEST_PARAMS,\n",
    "        'feature_importance_file': 'feature_importance_v2_baseline.csv'\n",
    "    }\n",
    "    \n",
    "    # Save the complete model package\n",
    "    joblib.dump(model_artifacts, 'champion.pkl')\n",
    "    \n",
    "    return model_artifacts\n",
    "\n",
    "# Run the training\n",
    "if __name__ == \"__main__\":\n",
    "    train_final_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
