{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8310326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73b611b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "X_train_input = np.load(\"Data/X_train.npy\")  # shape (700, 6)\n",
    "Y_train_input = np.load(\"Data/Y_train.npy\")  # shape (700,)\n",
    "\n",
    "# Random train/test split (100 for test, 600 for training)\n",
    "X_train_cv, X_test_holdout, Y_train_cv, Y_test_holdout = train_test_split(\n",
    "    X_train_input, Y_train_input, test_size=300, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_cv_scaled = scaler.fit_transform(X_train_cv)\n",
    "X_test_holdout_scaled = scaler.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3cb6473",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_cv_scaled = scaler.fit_transform(X_train_cv)\n",
    "X_test_holdout_scaled = scaler.transform(X_test_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14158892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RBF transformation function\n",
    "def rbf_transform(X, centers, sigma):\n",
    "    diff = X[:, np.newaxis, :] - centers[np.newaxis, :, :]\n",
    "    return np.exp(-np.sum(diff**2, axis=2) / (2 * sigma**2))\n",
    "\n",
    "# Hyperparameter grids - Initial\n",
    "#sigma_list = [0.1, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0]\n",
    "#n_centers_list = [20, 30, 40, 50, 100, 125, 150, 200]\n",
    "#alpha_list = [0.001, 0.005, 0.01, 0.1, 1.0, 10.0]\n",
    "\n",
    "# Hyperparameter grids - Specialized\n",
    "sigma_list = [0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 4.0]\n",
    "n_centers_list = [150, 175, 200, 225, 250]\n",
    "alpha_list = [0.0005, 0.00075, 0.001, 0.005, 0.01]\n",
    "\n",
    "\n",
    "# K-Fold CV\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_r2 = -np.inf\n",
    "best_params = None\n",
    "\n",
    "# Example: results = [{'sigma': s, 'n_centers': n, 'alpha': a, 'mean_r2': r2}, ...]\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8a3548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Cross Validation R2: 0.9606201088393866\n",
      "Best Hyperparameters: {'sigma': 2.5, 'n_centers': 250, 'alpha': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "for sigma, n_centers, alpha in product(sigma_list, n_centers_list, alpha_list):\n",
    "    \n",
    "    r2_scores = []\n",
    "    \n",
    "    for train_idx, val_idx in kf.split(X_train_cv_scaled):\n",
    "        X_tr, X_val = X_train_cv_scaled[train_idx], X_train_cv_scaled[val_idx]\n",
    "        Y_tr, Y_val = Y_train_cv[train_idx], Y_train_cv[val_idx]\n",
    "        \n",
    "        # KMeans centers on training fold\n",
    "        kmeans = KMeans(n_clusters=n_centers, random_state=42).fit(X_tr)\n",
    "        centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Transform both training and validation data\n",
    "        X_tr_rbf = rbf_transform(X_tr, centers, sigma)\n",
    "        X_val_rbf = rbf_transform(X_val, centers, sigma)\n",
    "        \n",
    "        # Train Ridge regression\n",
    "        model = Ridge(alpha=alpha)\n",
    "        model.fit(X_tr_rbf, Y_tr)\n",
    "        \n",
    "        # Predict on validation fold\n",
    "        Y_val_pred = model.predict(X_val_rbf)\n",
    "        r2_scores.append(r2_score(Y_val, Y_val_pred))\n",
    "    \n",
    "    mean_r2 = np.mean(r2_scores)\n",
    "    results.append({'sigma': sigma, 'n_centers': n_centers, 'alpha': alpha, 'mean_r2': mean_r2})\n",
    "    \n",
    "    if mean_r2 > best_r2:\n",
    "        best_r2 = mean_r2\n",
    "        best_params = {'sigma': sigma, 'n_centers': n_centers, 'alpha': alpha}\n",
    "\n",
    "print(\"Best Cross Validation R2:\", best_r2)\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8925a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on held-out 100 test samples: 0.9697717973342667\n"
     ]
    }
   ],
   "source": [
    "# Refit model on all 600 training samples using best hyperparameters\n",
    "sigma_best = best_params['sigma']\n",
    "n_centers_best = best_params['n_centers']\n",
    "alpha_best = best_params['alpha']\n",
    "\n",
    "# KMeans centers on full training fold\n",
    "kmeans = KMeans(n_clusters=n_centers_best, random_state=42).fit(X_train_cv_scaled)\n",
    "centers_best = kmeans.cluster_centers_\n",
    "\n",
    "# Transform training and test data\n",
    "X_train_rbf = rbf_transform(X_train_cv_scaled, centers_best, sigma_best)\n",
    "X_test_rbf = rbf_transform(X_test_holdout_scaled, centers_best, sigma_best)\n",
    "\n",
    "# Train final model\n",
    "final_model = Ridge(alpha=alpha_best)\n",
    "final_model.fit(X_train_rbf, Y_train_cv)\n",
    "\n",
    "# Predict on held-out 100 samples\n",
    "Y_test_pred = final_model.predict(X_test_rbf)\n",
    "test_r2 = r2_score(Y_test_holdout, Y_test_pred)\n",
    "print(\"R2 on held-out 100 test samples:\", test_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe79dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Valores preditos\n",
    "Y_pred = final_model.predict(X_test_rbf)\n",
    "test_r2 = r2_score(Y_test_holdout, Y_pred)\n",
    "print(\"R² on held-out test samples:\", test_r2)\n",
    "\n",
    "# Scatter plot: y_real vs y_pred\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(Y_test_holdout, Y_pred, alpha=0.7)\n",
    "plt.plot([Y_test_holdout.min(), Y_test_holdout.max()],\n",
    "         [Y_test_holdout.min(), Y_test_holdout.max()],\n",
    "         'r--', label='Ideal fit')\n",
    "plt.xlabel(\"Valores reais\")\n",
    "plt.ylabel(\"Valores previstos\")\n",
    "plt.title(\"RBF Ridge: Predição vs Real\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
